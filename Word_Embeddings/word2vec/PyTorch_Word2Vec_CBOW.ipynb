{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2519c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc2519c3",
        "outputId": "0db1d0d7-d1ce-406d-f9df-d64afe0ea064"
      },
      "outputs": [],
      "source": [
        "import sys  \n",
        "!{sys.executable} -m pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f1c94eea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1c94eea",
        "outputId": "9ae1a82e-b4d2-41f4-9212-0e3fccb97fb9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "import contractions\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "92930072",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92930072",
        "outputId": "9345b646-773e-4ddc-8392-24a5df821957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f33b0242750>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40693546",
      "metadata": {
        "id": "40693546"
      },
      "source": [
        "# Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "724f74a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724f74a2",
        "outputId": "a2f789b4-5202-4d97-a8cf-784f7922a229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268151\n"
          ]
        }
      ],
      "source": [
        "# Import txt file\n",
        "\n",
        "file = open('/content/raw_gatsby.txt', 'r')\n",
        "raw_gatsby = file.read()\n",
        "file.close()\n",
        "print(len(raw_gatsby))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c8fe45c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8fe45c8",
        "outputId": "5d702cf0-d77c-4472-cfc9-f98c443eea12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "261535\n",
            "In my younger and more vulnerable years my father gave me some advice that I have been turning over in my mind ever since. Whenever you feel like criticizing anyone he told me just remember that all the people in this world have not had the advantages that you have had. He did not say any more but we have always been unusually communicative in a reserved way and I understood that he meant a great deal more than that. In consequence I am inclined to reserve all judgements a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores. The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person and so it came about that in college I was unjustly accused of being a politician because I was privy to the secret griefs of wild unknown men. Most of the confidences were unsought frequently I have feigned sleep preoccupation or a hostile levity when I realized by some unmistakable sign that an intimate r\n"
          ]
        }
      ],
      "source": [
        "# Cleaning Data\n",
        "\n",
        "# Replace quotation marks, commas, colons, and semicolons with blank space; line breaks, double spaces, and hyphens with a space\n",
        "clean_gatsby_start = raw_gatsby.replace('“', '').replace('”', '').replace(';', '').replace(':', '').replace('\\n', ' ').replace(',', ''). replace('  ', ' '). replace('-', ' ').replace('—', ' ')\n",
        "#clean_gatsby_mid = clean_gatsby_start.replace('.', '')\n",
        "\n",
        "# Remove contractions and return whole words\n",
        "clean_gatsby = contractions.fix(clean_gatsby_start)\n",
        "\n",
        "# Remove leftover punctuaction \n",
        "clean_gatsby = clean_gatsby.replace('’', '')\n",
        "\n",
        "\n",
        "\n",
        "print(len(clean_gatsby))\n",
        "print(clean_gatsby[:1000]) # Indices are characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6e5edba5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e5edba5",
        "outputId": "b704e27e-5d0d-455b-ff28-405c466c6e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "257952\n",
            "In my younger and more vulnerable years my father gave me some advice that I have been turning over in my mind ever since Whenever you feel like criticizing anyone he told me just remember that all the people in this world have not had the advantages that you have had He did not say any more but we have always been unusually communicative in a reserved way and I understood that he meant a great deal more than that In consequence I am inclined to reserve all judgements a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person and so it came about that in college I was unjustly accused of being a politician because I was privy to the secret griefs of wild unknown men Most of the confidences were unsought frequently I have feigned sleep preoccupation or a hostile levity when I realized by some unmistakable sign that an intimate revela\n"
          ]
        }
      ],
      "source": [
        "# Remove Puncuation\n",
        "\n",
        "g_no_punc = clean_gatsby.translate(str.maketrans('', '', string.punctuation))\n",
        "print(len(g_no_punc))\n",
        "print(g_no_punc[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f34c3d0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f34c3d0b",
        "outputId": "f2289a6b-c124-4df0-a33d-dd3402226f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6251\n"
          ]
        }
      ],
      "source": [
        "no_punc_token = word_tokenize(g_no_punc)\n",
        "\n",
        "vocab = set(no_punc_token)\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc88dda",
      "metadata": {
        "id": "fdc88dda"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1030add4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1030add4",
        "outputId": "f5e4ed55-1643-4a4e-dc89-5a999ff39550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49748\n",
            "(['my', 'In'], 'younger')\n",
            "[([1589, 1598], 5456), ([5456, 1589], 6022), ([6022, 5456], 4938)]\n"
          ]
        }
      ],
      "source": [
        "# Set Hyperparameters\n",
        "\n",
        "CONTEXT_SIZE = 2\n",
        "embed_dims = 10\n",
        "vocab_size = len(vocab)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "# Create a word to index dict\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ngrams = [\n",
        "    (\n",
        "        [no_punc_token[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
        "        no_punc_token[i]\n",
        "    )\n",
        "    for i in range(CONTEXT_SIZE, len(no_punc_token))\n",
        "]\n",
        "\n",
        "\n",
        "# Create a list of format ([c1, c2], t) for DataLoader\n",
        "\n",
        "word_idx_list = []\n",
        "for i, (c, t) in enumerate(ngrams):\n",
        "    context = [word_to_ix[w] for w in c]\n",
        "    target = word_to_ix[t]\n",
        "    word_idx_list.insert(i, (context, target))\n",
        "\n",
        "    \n",
        "print(len(ngrams))\n",
        "print(ngrams[0])\n",
        "print(word_idx_list[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8f518d4a",
      "metadata": {
        "id": "8f518d4a"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset and DataLoader\n",
        "\n",
        "class GatsDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        print('Data: ', self.data[0])\n",
        "        self.len = len(data)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    \n",
        "# Custom Collate Function to correctly shape data with batch size\n",
        "\n",
        "def custom_collate(data):\n",
        "    context = [idx[0] for idx in data]\n",
        "    target = [idx[1] for idx in data]\n",
        "    return torch.tensor(context), torch.tensor(target)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "deec78b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deec78b2",
        "outputId": "d5c6e0e1-b8ec-41df-b5e6-26f90bc76841",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data:  ([1589, 1598], 5456)\n",
            "(tensor([[1589, 1598],\n",
            "        [5456, 1589],\n",
            "        [6022, 5456],\n",
            "        [4938, 6022],\n",
            "        [1792, 4938],\n",
            "        [5038, 1792],\n",
            "        [1589, 5038],\n",
            "        [4819, 1589],\n",
            "        [4719, 4819],\n",
            "        [1077, 4719],\n",
            "        [ 302, 1077],\n",
            "        [1183,  302],\n",
            "        [5274, 1183],\n",
            "        [5751, 5274],\n",
            "        [4097, 5751],\n",
            "        [3863, 4097],\n",
            "        [1103, 3863],\n",
            "        [ 850, 1103],\n",
            "        [ 265,  850],\n",
            "        [1589,  265],\n",
            "        [1347, 1589],\n",
            "        [4959, 1347],\n",
            "        [ 907, 4959],\n",
            "        [5780,  907],\n",
            "        [5168, 5780],\n",
            "        [ 256, 5168],\n",
            "        [ 542,  256],\n",
            "        [2769,  542],\n",
            "        [1942, 2769],\n",
            "        [5298, 1942],\n",
            "        [3546, 5298],\n",
            "        [1077, 3546],\n",
            "        [5956, 1077],\n",
            "        [5391, 5956],\n",
            "        [5274, 5391],\n",
            "        [2135, 5274],\n",
            "        [5431, 2135],\n",
            "        [ 519, 5431],\n",
            "        [ 265,  519],\n",
            "        [   3,  265],\n",
            "        [1114,    3],\n",
            "        [4097, 1114],\n",
            "        [4310, 4097],\n",
            "        [3428, 4310],\n",
            "        [5431, 3428],\n",
            "        [2084, 5431],\n",
            "        [5274, 2084],\n",
            "        [5168, 5274],\n",
            "        [4097, 5168],\n",
            "        [3428, 4097],\n",
            "        [1356, 3428],\n",
            "        [ 486, 1356],\n",
            "        [4310,  486],\n",
            "        [ 466, 4310],\n",
            "        [2296,  466],\n",
            "        [4938, 2296],\n",
            "        [3497, 4938],\n",
            "        [4101, 3497],\n",
            "        [4097, 4101],\n",
            "        [1329, 4097],\n",
            "        [3863, 1329],\n",
            "        [3283, 3863],\n",
            "        [5848, 3283],\n",
            "        [ 265, 5848],\n",
            "        [1122,  265],\n",
            "        [4914, 1122],\n",
            "        [3181, 4914],\n",
            "        [6022, 3181],\n",
            "        [5751, 6022],\n",
            "        [2487, 5751],\n",
            "        [5274, 2487],\n",
            "        [5298, 5274],\n",
            "        [1431, 5298],\n",
            "        [1122, 1431],\n",
            "        [3541, 1122],\n",
            "        [4512, 3541],\n",
            "        [4938, 4512],\n",
            "        [3593, 4938],\n",
            "        [5274, 3593],\n",
            "        [1598, 5274],\n",
            "        [4292, 1598],\n",
            "        [5751, 4292],\n",
            "        [5474, 5751],\n",
            "        [1362, 5474],\n",
            "        [5762, 1362],\n",
            "        [1867, 5762],\n",
            "        [2135, 1867],\n",
            "        [1947, 2135],\n",
            "        [1122, 1947],\n",
            "        [5914, 1122],\n",
            "        [5274, 5914],\n",
            "        [5109, 5274],\n",
            "        [3908, 5109],\n",
            "        [3495, 3908],\n",
            "        [5705, 3495],\n",
            "        [2602, 5705],\n",
            "        [2784, 2602],\n",
            "        [5762, 2784],\n",
            "        [1077, 5762],\n",
            "        [6022, 1077],\n",
            "        [  69, 6022],\n",
            "        [2488,   69],\n",
            "        [1077, 2488],\n",
            "        [5431, 1077],\n",
            "        [5326, 5431],\n",
            "        [ 430, 5326],\n",
            "        [4310,  430],\n",
            "        [1122, 4310],\n",
            "        [ 121, 1122],\n",
            "        [1405,  121],\n",
            "        [3174, 1405],\n",
            "        [6041, 3174],\n",
            "        [5223, 6041],\n",
            "        [1347, 5223],\n",
            "        [6072, 1347],\n",
            "        [ 801, 6072],\n",
            "        [5762,  801],\n",
            "        [5214, 5762],\n",
            "        [6022, 5214],\n",
            "        [3757, 6022],\n",
            "        [5695, 3757],\n",
            "        [5762, 5695],\n",
            "        [   3, 5762],\n",
            "        [4837,    3],\n",
            "        [4495, 4837],\n",
            "        [5556, 4495],\n",
            "        [1521, 5556],\n",
            "        [ 265, 1521]]), tensor([5456, 6022, 4938, 1792, 5038, 1589, 4819, 4719, 1077,  302, 1183, 5274,\n",
            "        5751, 4097, 3863, 1103,  850,  265, 1589, 1347, 4959,  907, 5780, 5168,\n",
            "         256,  542, 2769, 1942, 5298, 3546, 1077, 5956, 5391, 5274, 2135, 5431,\n",
            "         519,  265,    3, 1114, 4097, 4310, 3428, 5431, 2084, 5274, 5168, 4097,\n",
            "        3428, 1356,  486, 4310,  466, 2296, 4938, 3497, 4101, 4097, 1329, 3863,\n",
            "        3283, 5848,  265, 1122, 4914, 3181, 6022, 5751, 2487, 5274, 5298, 1431,\n",
            "        1122, 3541, 4512, 4938, 3593, 5274, 1598, 4292, 5751, 5474, 1362, 5762,\n",
            "        1867, 2135, 1947, 1122, 5914, 5274, 5109, 3908, 3495, 5705, 2602, 2784,\n",
            "        5762, 1077, 6022,   69, 2488, 1077, 5431, 5326,  430, 4310, 1122,  121,\n",
            "        1405, 3174, 6041, 5223, 1347, 6072,  801, 5762, 5214, 6022, 3757, 5695,\n",
            "        5762,    3, 4837, 4495, 5556, 1521,  265, 1122]))\n"
          ]
        }
      ],
      "source": [
        "# Call Dataset and DataLoader\n",
        "\n",
        "dataset = GatsDataset(word_idx_list)\n",
        "train_loader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = False, collate_fn = custom_collate, drop_last = True)\n",
        "\n",
        "\n",
        "for data in train_loader:\n",
        "    print(data)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fba590e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fba590e0",
        "outputId": "072999d2-a859-4e39-8d3b-796b97038033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 11.5 ms, sys: 1.82 ms, total: 13.4 ms\n",
            "Wall time: 16.8 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Class Creation\n",
        "\n",
        "class word2vec(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, context_size, batch_size):\n",
        "        super(word2vec, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        \n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view(self.batch_size, -1)\n",
        "        out_1 = F.relu(self.linear1(embeds))\n",
        "        out_2 = self.linear2(out_1)\n",
        "        out_f = F.log_softmax(out_2, dim = 1)\n",
        "        return out_f\n",
        "    \n",
        "    def f_predict(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view(1, -1)\n",
        "        out_1 = F.relu(self.linear1(embeds))\n",
        "        out_2 = self.linear2(out_1)\n",
        "        out_f = F.log_softmax(out_2, dim = 1)\n",
        "        return out_f\n",
        "        \n",
        "    def predict(self, contexts):\n",
        "        inputs = torch.tensor([word_to_ix[w] for w in contexts], dtype = torch.long)\n",
        "        y_pred = self.f_predict(inputs)\n",
        "        idx = torch.argmax(y_pred)\n",
        "        target_pred = [k for k, v in word_to_ix.items() if v == idx]\n",
        "        return target_pred                    \n",
        "    \n",
        "    \n",
        "\n",
        "# Call word2vec with hyperparameters, declare loss function and optimizer with learning rate\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "gats_model = word2vec(vocab_size, embed_dims, CONTEXT_SIZE, BATCH_SIZE)\n",
        "optimizer = optim.SGD(gats_model.parameters(), lr = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "565ca11b",
      "metadata": {
        "id": "565ca11b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# First Method - For Loop time trial\n",
        "# Params: context_size = 2, lr = 0.001, NLLLoss function, log_softmax\n",
        "# Epochs: 5 - 9min 24s\n",
        "# End Error: 322202.3 (-15.14%)\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0.0\n",
        "    \n",
        "    for context, target in ngrams:\n",
        "        context_ids = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
        "        gats_model.zero_grad() # PyTorch accumulates gradients so has to be zeroed from previous loop        \n",
        "        log_probs = gats_model(context_ids)\n",
        "        target = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
        "        loss = loss_function(log_probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "    print(total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039ccbc0",
      "metadata": {
        "id": "039ccbc0",
        "outputId": "dee37f87-8ee7-4ed7-958b-1bd18396bef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2953.564935684204\n",
            "1750.248473405838\n",
            "1434.6276547908783\n",
            "1292.9717783927917\n",
            "1208.4133656024933\n",
            "1148.7557430267334\n",
            "1102.2296936511993\n",
            "1063.4776307344437\n",
            "CPU times: user 2h 36min 31s, sys: 2h 4min 57s, total: 4h 41min 28s\n",
            "Wall time: 48min 23s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Second Method - Dataloader Batches time trial\n",
        "# Params: context_size = 2, lr = 0.001, NLLLoss function, log_softmax, 5 epochs\n",
        "# Batch: 128 - 38.4s, 64 - 56.8s, 32 - 1min 14s\n",
        "# End Error: 128 - 3607.4 (-1.78%), 64 - 7113.2 (-3.77%), 32 - 13480.6 (-7.15%)\n",
        "\n",
        "for epoch in range(400):\n",
        "    total_loss = 0.0\n",
        "    for context, target in train_loader:\n",
        "        gats_model.zero_grad()\n",
        "        log_probs = gats_model(context)\n",
        "        loss = loss_function(log_probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    \n",
        "    if epoch % 50 == 0:\n",
        "        print(total_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fad685",
      "metadata": {
        "id": "31fad685",
        "outputId": "d5a80713-a0cf-4a51-9491-eea52f96642c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['largest']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict next word given 2 context words\n",
        "\n",
        "gats_model.predict(['Gatsbys', 'house'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
