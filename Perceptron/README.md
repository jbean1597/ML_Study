# Perceptron

In this project, the first steps were taken to understand the basics of neural networks and how they function in a simplified sense. Starting with a 
single input layer of ```3``` neurons and an output of just ```1```.  These neurons were all connected with ```weights``` and ```biases``` such that 
some neurons had a stronger effect on the activation of the output in the forward pass. This concept as an equation is

>**activation = &sum;(w<sub>i</sub>x<sub>i</sub> + b)**

